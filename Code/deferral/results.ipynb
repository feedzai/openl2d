{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import yaml\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "data_cfg_path = '../alert_data/dataset_cfg.yaml'\n",
    "with open(data_cfg_path, 'r') as infile:\n",
    "    data_cfg = yaml.safe_load(infile)\n",
    "\n",
    "cat_dict = data_cfg['categorical_dict']\n",
    "\n",
    "test_env_df = pd.DataFrame(columns = ['training_seed',\n",
    "                                        'method',\n",
    "                                        'batch_size',\n",
    "                                        'batch_seed', \n",
    "                                        'team',\n",
    "                                        'distribution', \n",
    "                                        'distribution_seed', \n",
    "                                        'n_errors',\n",
    "                                        'tp',\n",
    "                                        'fp',\n",
    "                                        'fn',\n",
    "                                        'tn',\n",
    "                                        'tpr',\n",
    "                                        'fpr',\n",
    "                                        'fpr_disp'])\n",
    "\n",
    "alerts = pd.read_parquet(f'../../FiFAR/alert_data/processed_data/alerts.parquet')\n",
    "test = alerts.loc[alerts['month'] == 7]\n",
    "for method in os.listdir('../../FiFAR/deferral/results/'):\n",
    "    if method not in ['OvA','Random','DeCCaF']:\n",
    "        training_seed = 'NA'\n",
    "        for cc in os.listdir(f'../../FiFAR/deferral/results/{method}'):\n",
    "            \n",
    "            env = cc.split('#')[1]\n",
    "            team = env.split('-')[0]\n",
    "\n",
    "            if env.split('-')[1] == 'hom':\n",
    "                distribution = 'hom'\n",
    "                distribution_seed = 'NA'\n",
    "            else:\n",
    "                distribution = 'var'\n",
    "                distribution_seed = env.split('-')[1].split('_')[1]\n",
    "\n",
    "            batch_size = 4457\n",
    "            batch_seed = 1\n",
    "\n",
    "            assignments = pd.read_parquet(f'../../FiFAR/deferral/results/{method}/{cc}/assignments.parquet')\n",
    "            reviews = pd.read_parquet(f'../../FiFAR/deferral/results/{method}/{cc}/results.parquet')\n",
    "            reviews = reviews['prediction']\n",
    "\n",
    "            labels = test.loc[reviews.index,'fraud_bool']\n",
    "\n",
    "            n_errors = (reviews != labels).astype(int).mean()\n",
    "            tn, fp, fn, tp = confusion_matrix(y_true = labels, y_pred = reviews).ravel()\n",
    "            tpr = tp/(tp+fn)\n",
    "            fpr = fp/(fp+tn)\n",
    "            \n",
    "            sub_test = test.loc[reviews.index,:]\n",
    "            old_ix = sub_test.loc[test['customer_age'] >= 50].index\n",
    "            yng_ix = sub_test.loc[test['customer_age'] < 50].index\n",
    "\n",
    "\n",
    "            old_pred = reviews.loc[old_ix]\n",
    "            old_label = labels.loc[old_ix]\n",
    "            fp_old = ((old_pred == 1) & (old_label == 0)).astype(int).sum()\n",
    "            tn_old = ((old_pred == 0) & (old_label == 0)).astype(int).sum()\n",
    "\n",
    "            yng_pred = reviews.loc[yng_ix]\n",
    "            yng_label = labels.loc[yng_ix]\n",
    "            fp_yng = ((yng_pred == 1) & (yng_label == 0)).astype(int).sum()\n",
    "            tn_yng = ((yng_pred == 0) & (yng_label == 0)).astype(int).sum()\n",
    "\n",
    "            fpr_yng = fp_yng/(fp_yng + tn_yng)\n",
    "            fpr_old = fp_old/(fp_old + tn_old)\n",
    "\n",
    "            fpr_disp =  fpr_yng/fpr_old\n",
    "\n",
    "            test_env_df = test_env_df.append(pd.Series([training_seed,method,batch_size, \n",
    "                                                        batch_seed, \n",
    "                                                        team,\n",
    "                                                        distribution,\n",
    "                                                        distribution_seed, \n",
    "                                                        n_errors,\n",
    "                                                        tp,\n",
    "                                                        fp,\n",
    "                                                        fn,\n",
    "                                                        tn,\n",
    "                                                        tpr,\n",
    "                                                        fpr, \n",
    "                                                        fpr_disp], index = test_env_df.columns), ignore_index = True)\n",
    "    if method in ['OvA','Random','DeCCaF']:\n",
    "        for seed in os.listdir(f'../../FiFAR/deferral/results/{method}'):\n",
    "            training_seed = seed\n",
    "            for cc in os.listdir(f'../../FiFAR/deferral/results/{method}/{seed}'):\n",
    "                \n",
    "                env = cc.split('#')[1]\n",
    "                team = env.split('-')[0]\n",
    "\n",
    "                if env.split('-')[1] == 'hom':\n",
    "                    distribution = 'hom'\n",
    "                    distribution_seed = 'NA'\n",
    "                else:\n",
    "                    distribution = 'var'\n",
    "                    distribution_seed = env.split('-')[1].split('_')[1]\n",
    "\n",
    "                batch_size = 4457\n",
    "                batch_seed = 1\n",
    "\n",
    "                assignments = pd.read_parquet(f'../../FiFAR/deferral/results/{method}/{seed}/{cc}/assignments.parquet')\n",
    "                reviews = pd.read_parquet(f'../../FiFAR/deferral/results/{method}/{seed}/{cc}/results.parquet')\n",
    "                reviews = reviews['prediction']\n",
    "\n",
    "                labels = test.loc[reviews.index,'fraud_bool']\n",
    "\n",
    "                n_errors = (reviews != labels).astype(int).mean()\n",
    "                tn, fp, fn, tp = confusion_matrix(y_true = labels, y_pred = reviews).ravel()\n",
    "                tpr = tp/(tp+fn)\n",
    "                fpr = fp/(fp+tn)\n",
    "                \n",
    "                sub_test = test.loc[reviews.index,:]\n",
    "                old_ix = sub_test.loc[test['customer_age'] >= 50].index\n",
    "                yng_ix = sub_test.loc[test['customer_age'] < 50].index\n",
    "\n",
    "\n",
    "                old_pred = reviews.loc[old_ix]\n",
    "                old_label = labels.loc[old_ix]\n",
    "                fp_old = ((old_pred == 1) & (old_label == 0)).astype(int).sum()\n",
    "                tn_old = ((old_pred == 0) & (old_label == 0)).astype(int).sum()\n",
    "\n",
    "                yng_pred = reviews.loc[yng_ix]\n",
    "                yng_label = labels.loc[yng_ix]\n",
    "                fp_yng = ((yng_pred == 1) & (yng_label == 0)).astype(int).sum()\n",
    "                tn_yng = ((yng_pred == 0) & (yng_label == 0)).astype(int).sum()\n",
    "\n",
    "                fpr_yng = fp_yng/(fp_yng + tn_yng)\n",
    "                fpr_old = fp_old/(fp_old + tn_old)\n",
    "\n",
    "                fpr_disp =  fpr_yng/fpr_old\n",
    "\n",
    "                test_env_df = test_env_df.append(pd.Series([training_seed,method,batch_size, \n",
    "                                                            batch_seed, \n",
    "                                                            team,\n",
    "                                                            distribution,\n",
    "                                                            distribution_seed, \n",
    "                                                            n_errors,\n",
    "                                                            tp,\n",
    "                                                            fp,\n",
    "                                                            fn,\n",
    "                                                            tn,\n",
    "                                                            tpr,\n",
    "                                                            fpr, \n",
    "                                                            fpr_disp], index = test_env_df.columns), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env_df['loss'] = (test_env_df['fn'] + 0.057*test_env_df['fp']).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full Rejection</th>\n",
       "      <th>Only Classifier h</th>\n",
       "      <th>Random Deferral</th>\n",
       "      <th>OvA</th>\n",
       "      <th>DeCCaF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>team_1</th>\n",
       "      <td>213.5</td>\n",
       "      <td>204.0</td>\n",
       "      <td>$169.6 \\pm 2.53$</td>\n",
       "      <td>$151.7 \\pm 1.99$</td>\n",
       "      <td>$138.1 \\pm 5.14$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team_2</th>\n",
       "      <td>213.5</td>\n",
       "      <td>204.0</td>\n",
       "      <td>$157.8 \\pm 1.39$</td>\n",
       "      <td>$142.0 \\pm 1.61$</td>\n",
       "      <td>$145.3 \\pm 4.28$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team_3</th>\n",
       "      <td>213.5</td>\n",
       "      <td>204.0</td>\n",
       "      <td>$151.2 \\pm 1.84$</td>\n",
       "      <td>$131.3 \\pm 2.19$</td>\n",
       "      <td>$126.2 \\pm 4.52$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team_4</th>\n",
       "      <td>213.5</td>\n",
       "      <td>204.0</td>\n",
       "      <td>$163.1 \\pm 1.61$</td>\n",
       "      <td>$145.8 \\pm 3.51$</td>\n",
       "      <td>$141.6 \\pm 5.32$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team_5</th>\n",
       "      <td>213.5</td>\n",
       "      <td>204.0</td>\n",
       "      <td>$163.3 \\pm 1.58$</td>\n",
       "      <td>$141.2 \\pm 2.57$</td>\n",
       "      <td>$132.0 \\pm 1.93$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Full Rejection  Only Classifier h   Random Deferral               OvA  \\\n",
       "team_1           213.5              204.0  $169.6 \\pm 2.53$  $151.7 \\pm 1.99$   \n",
       "team_2           213.5              204.0  $157.8 \\pm 1.39$  $142.0 \\pm 1.61$   \n",
       "team_3           213.5              204.0  $151.2 \\pm 1.84$  $131.3 \\pm 2.19$   \n",
       "team_4           213.5              204.0  $163.1 \\pm 1.61$  $145.8 \\pm 3.51$   \n",
       "team_5           213.5              204.0  $163.3 \\pm 1.58$  $141.2 \\pm 2.57$   \n",
       "\n",
       "                  DeCCaF  \n",
       "team_1  $138.1 \\pm 5.14$  \n",
       "team_2  $145.3 \\pm 4.28$  \n",
       "team_3  $126.2 \\pm 4.52$  \n",
       "team_4  $141.6 \\pm 5.32$  \n",
       "team_5  $132.0 \\pm 1.93$  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = test_env_df.groupby(['method','team']).mean()['loss'].reset_index().round(1)\n",
    "import numpy as np\n",
    "temp = test_env_df.groupby(['method','team'])['loss'].agg(['mean','count','std'])\n",
    "b = (temp['std']*1.96/np.sqrt(temp['count'])).round(2).reset_index()\n",
    "\n",
    "table = pd.DataFrame(index = a['team'].unique())\n",
    "table['Full Rejection'] = a.loc[a['method'] == 'Full_Rej']['loss'].values\n",
    "table['Only Classifier h'] = a.loc[a['method'] == 'Only_Classifier']['loss'].values\n",
    "table['Random Deferral'] =  '$' + a.loc[a['method'] == 'Random']['loss'].astype(str).values + \" \\pm \" + b.loc[b['method'] == 'Random'][0].astype(str).values + '$'\n",
    "table['OvA'] =  r'$' + a.loc[a['method'] == 'OvA']['loss'].astype(str).values + \" \\pm \" + b.loc[b['method'] == 'OvA'][0].astype(str).values + '$'\n",
    "table['DeCCaF'] =  r'$' + a.loc[a['method'] == 'DeCCaF']['loss'].astype(str).values + \" \\pm \" + b.loc[b['method'] == 'DeCCaF'][0].astype(str).values + '$'\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11552795031055897"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a.loc[a['method'] == 'Random']['loss'].mean() - a.loc[a['method'] == 'OvA']['loss'].mean())/a.loc[a['method'] == 'Random']['loss'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15130434782608704"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a.loc[a['method'] == 'Random']['loss'].mean() - a.loc[a['method'] == 'DeCCaF']['loss'].mean())/a.loc[a['method'] == 'Random']['loss'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "import numpy as np\n",
    "with open(f'../../FiFAR/deferral/l2d_predictions/ova.pkl', 'rb') as infile:\n",
    "        ova = pickle.load(infile)\n",
    "with open(f'../../FiFAR/deferral/l2d_predictions/deccaf.pkl', 'rb') as infile:\n",
    "        deccaf = pickle.load(infile)\n",
    "\n",
    "data = pd.read_parquet(f'../../FiFAR/alert_data/processed_data/alerts.parquet')\n",
    "val = data.loc[data['month'] == 6]\n",
    "l = 0.057\n",
    "e_c = val['fraud_bool'].replace([0,1], [l,1]).mean()\n",
    "reb_1 = (val['fraud_bool'].mean()/e_c)\n",
    "reb_0 = (1-val['fraud_bool']).mean()*l/e_c\n",
    "test = data.loc[data['month'] == 7]\n",
    "nmin = len(test.loc[test['fraud_bool'] == 0])\n",
    "nmax = int(nmin*reb_1/reb_0)\n",
    "preds = pd.read_parquet(f'../../FiFAR/synthetic_experts/expert_predictions.parquet').loc[data.index]\n",
    "auc = pd.DataFrame()\n",
    "ece = pd.DataFrame()\n",
    "a = preds.loc[test.index]\n",
    "b = test['fraud_bool']\n",
    "oversampled = pd.concat([test.loc[test['fraud_bool'] == 0], test.loc[test['fraud_bool'] == 1].sample(replace=True, n = nmax, random_state=42)]).index\n",
    "i=1\n",
    "for seed in ova:\n",
    "    batch, team = seed.split('#') \n",
    "    for expert in ova[seed].columns.drop('classifier_h'):\n",
    "        outcomes = (a.loc[oversampled,expert] == b.loc[oversampled]).astype(int)\n",
    "        auc.loc[i,'batch'] = batch\n",
    "        auc.loc[i,'team'] = team\n",
    "        auc.loc[i,'expert'] = expert\n",
    "        auc.loc[i,'auc_ova'] = (roc_auc_score(y_true = outcomes, y_score = ova[seed].loc[oversampled,expert]))\n",
    "        prob_true, prob_pred = calibration_curve(y_true = outcomes, y_prob = ova[seed].loc[oversampled,expert], strategy='quantile', n_bins = 10)\n",
    "        auc.loc[i,'ece_ova'] = (np.mean(np.abs(prob_true - prob_pred)))\n",
    "        auc.loc[i,'auc_deccaf'] = (roc_auc_score(y_true = outcomes, y_score = deccaf[seed].loc[oversampled,expert]))\n",
    "        prob_true, prob_pred = calibration_curve(y_true = outcomes, y_prob = deccaf[seed].loc[oversampled,expert], strategy='quantile', n_bins = 10)\n",
    "        auc.loc[i,'ece_deccaf'] = (np.mean(np.abs(prob_true - prob_pred)))\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo.alves/anaconda3/envs/openl2d-env/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03990758522753857"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(auc.mean()['auc_deccaf'] - auc.mean()['auc_ova'])/auc.mean()['auc_ova']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonardo.alves/anaconda3/envs/openl2d-env/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1750215570868043"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(auc.mean()['ece_ova']- auc.mean()['ece_deccaf'])/auc.mean()['ece_ova']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame()\n",
    "temp = auc.groupby(by = ['team'])['auc_ova'].agg(['mean','count','std'])\n",
    "mean = temp['mean']\n",
    "ci = (temp['std']*1.96/np.sqrt(temp['count'])).round(2)\n",
    "table['auc_ova'] = '$' + mean.round(2).astype(str) + \"\\pm\" + ci.astype(str) + '$'\n",
    "\n",
    "temp = auc.groupby(by = ['team'])['ece_ova'].agg(['mean','count','std'])\n",
    "mean = temp['mean']*100\n",
    "ci = (temp['std']*100*1.96/np.sqrt(temp['count'])).round(1)\n",
    "table['ece_ova'] = '$' + mean.round(1).astype(str) + \"\\pm\" + ci.astype(str) + '$'\n",
    "\n",
    "temp = auc.groupby(by = ['team'])['auc_deccaf'].agg(['mean','count','std'])\n",
    "mean = temp['mean']\n",
    "ci = (temp['std']*1.96/np.sqrt(temp['count'])).round(2)\n",
    "table['auc_deccaf'] = '$' + mean.round(2).astype(str) + \"\\pm\" + ci.astype(str) + '$'\n",
    "\n",
    "temp = auc.groupby(by = ['team'])['ece_deccaf'].agg(['mean','count','std'])\n",
    "mean = temp['mean']*100\n",
    "ci = (temp['std']*100*1.96/np.sqrt(temp['count'])).round(1)\n",
    "table['ece_deccaf'] = '$' + mean.round(1).astype(str) + \"\\pm\" + ci.astype(str) + '$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc_ova</th>\n",
       "      <th>ece_ova</th>\n",
       "      <th>auc_deccaf</th>\n",
       "      <th>ece_deccaf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>team_1</th>\n",
       "      <td>$0.61\\pm0.01$</td>\n",
       "      <td>$6.0\\pm0.5$</td>\n",
       "      <td>$0.64\\pm0.02$</td>\n",
       "      <td>$4.6\\pm0.5$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team_2</th>\n",
       "      <td>$0.58\\pm0.01$</td>\n",
       "      <td>$6.1\\pm0.6$</td>\n",
       "      <td>$0.6\\pm0.01$</td>\n",
       "      <td>$4.9\\pm0.4$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team_3</th>\n",
       "      <td>$0.6\\pm0.02$</td>\n",
       "      <td>$5.5\\pm0.5$</td>\n",
       "      <td>$0.62\\pm0.02$</td>\n",
       "      <td>$5.3\\pm0.6$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team_4</th>\n",
       "      <td>$0.59\\pm0.01$</td>\n",
       "      <td>$5.3\\pm0.6$</td>\n",
       "      <td>$0.6\\pm0.01$</td>\n",
       "      <td>$3.9\\pm0.4$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team_5</th>\n",
       "      <td>$0.59\\pm0.01$</td>\n",
       "      <td>$5.6\\pm0.7$</td>\n",
       "      <td>$0.61\\pm0.01$</td>\n",
       "      <td>$4.9\\pm0.6$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              auc_ova      ece_ova     auc_deccaf   ece_deccaf\n",
       "team                                                          \n",
       "team_1  $0.61\\pm0.01$  $6.0\\pm0.5$  $0.64\\pm0.02$  $4.6\\pm0.5$\n",
       "team_2  $0.58\\pm0.01$  $6.1\\pm0.6$   $0.6\\pm0.01$  $4.9\\pm0.4$\n",
       "team_3   $0.6\\pm0.02$  $5.5\\pm0.5$  $0.62\\pm0.02$  $5.3\\pm0.6$\n",
       "team_4  $0.59\\pm0.01$  $5.3\\pm0.6$   $0.6\\pm0.01$  $3.9\\pm0.4$\n",
       "team_5  $0.59\\pm0.01$  $5.6\\pm0.7$  $0.61\\pm0.01$  $4.9\\pm0.6$"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7072718707150493\n",
      "4.843789647446122\n"
     ]
    }
   ],
   "source": [
    "test = alerts.loc[alerts['month'] == 7]\n",
    "exp_pred = pd.read_parquet(f'../../FiFAR/synthetic_experts/expert_predictions.parquet').loc[test.index]\n",
    "\n",
    "\n",
    "with open(f\"../../FiFAR/classifier_h/selected_model/best_model.pickle\", 'rb') as fp:\n",
    "    classifier_h = pickle.load(fp)\n",
    "with open(f\"../../FiFAR/classifier_h/selected_model/model_properties.yaml\", 'r') as fp:\n",
    "    classifier_h_properties = yaml.safe_load(fp)\n",
    "\n",
    "def sig(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def output(data, model, init_score):\n",
    "    return sig(model.predict(data,raw_score=True) + init_score)\n",
    "\n",
    "X_test = test.drop(columns = ['fraud_bool','model_score','month']) \n",
    "\n",
    "a = pd.Series(output(X_test, classifier_h, classifier_h_properties['init_score']), index = X_test.index)\n",
    "\n",
    "outcomes = b.loc[oversampled]\n",
    "prob_true, prob_pred = calibration_curve(y_true = outcomes, y_prob = a.loc[oversampled], strategy='quantile', n_bins = 10)\n",
    "\n",
    "\n",
    "print(roc_auc_score(y_true = outcomes, y_score = a.loc[oversampled]))\n",
    "print(np.mean(np.abs(prob_true - prob_pred))*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
